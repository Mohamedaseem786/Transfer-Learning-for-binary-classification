{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbFmQdsZs5eW"
      },
      "outputs": [],
      "source": [
        "# Import all the necessary files!\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from os import getcwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xJZ5glPPCRz"
      },
      "outputs": [],
      "source": [
        "path_inception = '/content/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "# Import the inception model\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# Create an instance of the inception model from the local pre-trained weights\n",
        "local_weights_file = path_inception\n",
        "\n",
        "pre_trained_model = InceptionV3(include_top = False,\n",
        "                                input_shape = (150, 150, 3),\n",
        "                                weights = None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "# Make all the layers in the pre-trained model non-trainable\n",
        "for layer in pre_trained_model.layers:\n",
        "  # Your Code Here\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the model summary\n",
        "# Write Your Code\n",
        "print('Name:             Register Number')"
      ],
      "metadata": {
        "id": "ZmkM_lzJuSNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFsUlwdfs_wg",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output.shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "# Expected Output:\n",
        "# ('last layer output shape: ', (None, 7, 7, 768))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bsWZWp5oMq9"
      },
      "outputs": [],
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 97.0%\n",
        "# Write your code here\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMXb913pbvFg"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Create the model(Write your code here)\n",
        "\n",
        "\n",
        "model = Model(pre_trained_model.input, outputs = x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile (#write your code here)\n"
      ],
      "metadata": {
        "id": "MHhv-q4Ava5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Name:          Register Number')\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "3sW8VHgbv1sA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HrnL_IQ8knWA"
      },
      "outputs": [],
      "source": [
        "# Get the Horse or Human dataset\n",
        "path_horse_or_human = '/content/horse-or-human.zip'\n",
        "# Get the Horse or Human Validation dataset\n",
        "path_validation_horse_or_human = '/content/validation-horse-or-human.zip'\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = path_horse_or_human\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/training')\n",
        "zip_ref.close()\n",
        "\n",
        "local_zip = path_validation_horse_or_human\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/validation')\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9okX7_ovskI"
      },
      "outputs": [],
      "source": [
        "# Define our example directories and files\n",
        "train_dir = '/tmp/training'\n",
        "validation_dir = '/tmp/validation'\n",
        "\n",
        "train_horses_dir = os.path.join(train_dir, 'horses')\n",
        "train_humans_dir = os.path.join(train_dir, 'humans')\n",
        "validation_horses_dir = os.path.join(validation_dir, 'horses')\n",
        "validation_humans_dir = os.path.join(validation_dir, 'humans')\n",
        "\n",
        "train_horses_fnames = os.listdir(train_horses_dir)\n",
        "train_humans_fnames = os.listdir(train_humans_dir)\n",
        "validation_horses_fnames = os.listdir(validation_horses_dir)\n",
        "validation_humans_fnames = os.listdir(validation_humans_dir)\n",
        "\n",
        "print(len(train_horses_fnames))\n",
        "print(len(train_humans_fnames))\n",
        "print(len(validation_horses_fnames))\n",
        "print(len(validation_humans_fnames))\n",
        "\n",
        "# Expected Output:\n",
        "# 500\n",
        "# 527\n",
        "# 128\n",
        "# 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4s8HckqGlnb"
      },
      "outputs": [],
      "source": [
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1/255,\n",
        "                                  height_shift_range = 0.2,\n",
        "                                  width_shift_range = 0.2,\n",
        "                                  horizontal_flip = True,\n",
        "                                  vertical_flip = True,\n",
        "                                  rotation_range = 0.4,\n",
        "                                  shear_range = 0.1,\n",
        "                                  zoom_range = 0.3,\n",
        "                                  fill_mode = 'nearest'\n",
        "                                  )\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale = 1/255)\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                   target_size = (150, 150),\n",
        "                                                   batch_size = 20,\n",
        "                                                   class_mode = 'binary',\n",
        "                                                   shuffle = True)\n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory(validation_dir,\n",
        "                                                        target_size = (150, 150),\n",
        "                                                        batch_size =20,\n",
        "                                                        class_mode = 'binary',\n",
        "                                                        shuffle = False)\n",
        "\n",
        "# Expected Output:\n",
        "# Found 1027 images belonging to 2 classes.\n",
        "# Found 256 images belonging to 2 classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Blhq2MAUeyGA"
      },
      "outputs": [],
      "source": [
        "# Run this and see how many epochs it should take before the callback\n",
        "# fires, and stops training at 97% accuracy\n",
        "\n",
        "callbacks = myCallback()\n",
        "history = model.fit(#write your code here)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2Fp6Se9rKuL"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Name:           Register Number:      ')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Name:           Register Number:      ')\n",
        "plt.title('Training and validation Loss')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "coursera": {
      "course_slug": "convolutional-neural-networks-tensorflow",
      "graded_item_id": "csg1x",
      "launcher_item_id": "GpKYz"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}